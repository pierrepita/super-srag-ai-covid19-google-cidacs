{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "### imports"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import pandas as pd\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import DateType\n#from pyspark.sql.functions import min, max"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nspark = SparkSession.builder.getOrCreate()\nTMP_BUCKET = \"ai-covid-tmp\"\nspark.conf.set(\"temporaryGcsBucket\", TMP_BUCKET)\nspark.sparkContext.setCheckpointDir(\"hdfs:///tmp/\")\nsc = spark.sparkContext"}, {"cell_type": "markdown", "metadata": {}, "source": "### download and read"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "--2021-06-01 11:02:28--  https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv\nResolving www.gstatic.com (www.gstatic.com)... 74.125.129.94, 2607:f8b0:4001:c56::5e\nConnecting to www.gstatic.com (www.gstatic.com)|74.125.129.94|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 545180722 (520M) [text/csv]\nSaving to: \u2018Global_Mobility_Report.csv\u2019\n\nGlobal_Mobility_Rep 100%[===================>] 519.92M   165MB/s    in 3.1s    \n\n2021-06-01 11:02:32 (165 MB/s) - \u2018Global_Mobility_Report.csv\u2019 saved [545180722/545180722]\n\nrenamed 'Global_Mobility_Report.csv' -> 'Global_Mobility_Report-28-05-2021.csv'\nput: `/googlemobility/data/Global_Mobility_Report-28-05-2021.csv': File exists\n"}], "source": "!hdfs dfs -mkdir -p /googlemobility/data/\n!wget 'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'\n!mv -fv 'Global_Mobility_Report.csv' 'Global_Mobility_Report-28-05-2021.csv'\n!hdfs dfs -put 'Global_Mobility_Report-28-05-2021.csv'  /googlemobility/data\ndf = spark.read.csv(\"hdfs:///googlemobility/data/Global_Mobility_Report-28-05-2021.csv\", header=True, inferSchema= True)"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "# puting ibge codes on municipalities and states\n# file from ftp://geoftp.ibge.gov.br/organizacao_do_territorio/estrutura_territorial/divisao_territorial/2018/DTB_2018.zip\n!hdfs dfs -put /RELATORIO_DTB_BRASIL_MUNICIPIO.csv /googlemobility/data/\nibge = spark.read.csv('hdfs:///googlemobility/data/RELATORIO_DTB_BRASIL_MUNICIPIO.csv', header=True, inferSchema= True)\nibge = ibge.withColumnRenamed('Nome_Munic\u00edpio', 'mun_name')\nibge = ibge.withColumnRenamed('C\u00f3digo Munic\u00edpio Completo', 'mun_code')"}, {"cell_type": "markdown", "metadata": {}, "source": "### writing on Google Cloud Storage"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "df.write.csv('gs://ai-covid19-datalake/raw/google-mobility/google-mobility_report-28-05-2021.csv', header=True, mode='overwrite')"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "ibge.write.csv('gs://ai-covid19-datalake/raw/ibge-data/ibge-municipality-to-code-28-05-2021.csv', header=True, mode='overwrite')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 96, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "5570\n5570\n"}], "source": "print(ibge.count())\nprint(ibge.dropDuplicates(['Nome_UF','mun_name']).count())"}, {"cell_type": "code", "execution_count": 88, "metadata": {}, "outputs": [], "source": "# FAZER JOIN USANDO O NOME DA CIDADE!\ncond = \ndf_joined = df.join(ibge, df['sub_region_2']==ibge['Nome_Munic\u00edpio'], 'left')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df"}, {"cell_type": "markdown", "metadata": {}, "source": "### some investigations"}, {"cell_type": "code", "execution_count": 89, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "1009775\n"}], "source": "print(df.count())"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "904413\n"}], "source": "# Is there Brazil's data? \ndf = df.filter(F.col('country_region_code') == \"BR\")\nprint(df.count())"}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "2020-02-15 2021-05-24\n"}], "source": "# which period? \ndf = df.withColumn('date', df.date.cast(DateType()))\n\n# df.groupBy('date').count().orderBy('date').show()\nmaxdate, mindate = df.select(F.max(\"date\"), F.min(\"date\")).first()\n\nprint(mindate, maxdate)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# how much states? "}, {"cell_type": "code", "execution_count": 70, "metadata": {}, "outputs": [], "source": "estados = df.select('sub_region_1').distinct()"}, {"cell_type": "code", "execution_count": 71, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "28\n+--------------------+\n|        sub_region_1|\n+--------------------+\n|State of Minas Ge...|\n|State of Esp\u00edrito...|\n|State of Mato Grosso|\n|      State of Goi\u00e1s|\n|State of Rio de J...|\n|    State of Roraima|\n|      State of Cear\u00e1|\n|     State of Paran\u00e1|\n|    State of Para\u00edba|\n|       State of Par\u00e1|\n|                null|\n|    State of Alagoas|\n|  State of S\u00e3o Paulo|\n|       State of Acre|\n|State of Rio Gran...|\n| State of Pernambuco|\n|  State of Tocantins|\n|State of Rio Gran...|\n|      State of Amap\u00e1|\n|   State of Rond\u00f4nia|\n|      State of Bahia|\n|State of Santa Ca...|\n|   State of Amazonas|\n|      State of Piau\u00ed|\n|State of Mato Gro...|\n|    State of Sergipe|\n|   State of Maranh\u00e3o|\n|    Federal District|\n+--------------------+\n\n"}], "source": "print(estados.count())\nestados.show(28)"}, {"cell_type": "code", "execution_count": 72, "metadata": {}, "outputs": [], "source": "cidades = df.select('sub_region_2').distinct()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# how much cities? "}, {"cell_type": "code", "execution_count": 75, "metadata": {}, "outputs": [], "source": "cidades = df.select('sub_region_2').distinct()"}, {"cell_type": "code", "execution_count": 76, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "2254\n+--------------------+\n|        sub_region_2|\n+--------------------+\n|            Araruama|\n|               Apodi|\n|Boa Esperan\u00e7a do Sul|\n|              Maruim|\n|    Senador Guiomard|\n|              Itatim|\n|  S\u00e3o Jo\u00e3o dos Patos|\n|  Ribas do Rio Pardo|\n|           Fronteira|\n|         Piranguinho|\n| Presidente Oleg\u00e1rio|\n|          Carl\u00f3polis|\n|             Ibipor\u00e3|\n|               Tapes|\n|       Guajar\u00e1-Mirim|\n|           Rancharia|\n|    Miranda do Norte|\n|     Barra do Bugres|\n|             Mantena|\n|             Aracati|\n+--------------------+\nonly showing top 20 rows\n\n"}], "source": "print(cidades.count())\ncidades.show(20)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# from which states, mostly? "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}