{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "pd.set_option(\"display.max_columns\", 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataviz\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag = spark.read.parquet('gs://ai-covid19-datalake/standard/super-srag/super_srag_v1.parquet').persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag.select('CLASSI_FIN').groupBy('CLASSI_FIN').count().orderBy('CLASSI_FIN').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result dataset\n",
    "df = spark.read.parquet('gs://ai-covid19-datalake/trusted/GBT-StratifiedSampleDatasets-3-RESULT.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('CLASSI_FIN_pred_000').groupBy('CLASSI_FIN_pred_000').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag = super_srag.filter((F.col('CLASSI_FIN') != '4') | (F.col('CLASSI_FIN').isNull()))\n",
    "super_srag = super_srag.withColumn('CLASSI_FIN_source', F.lit('original'))\n",
    "super_srag = super_srag.withColumn('ANO', F.substring(F.col('epi_week_year'), 4, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('CLASSI_FIN_source', F.lit('predicted'))\n",
    "df = df.drop('CLASSI_FIN').withColumnRenamed('CLASSI_FIN_pred_000', 'CLASSI_FIN')\n",
    "df = df.withColumn('CLASSI_FIN', F.when(F.col('CLASSI_FIN') == 1.0, '5').otherwise(F.lit('4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('CLASSI_FIN').groupBy('CLASSI_FIN').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag = super_srag.union(df.select(super_srag.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag.select('CLASSI_FIN').groupBy('CLASSI_FIN').count().orderBy('CLASSI_FIN').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting covid and not-covid cases (ignoring missing values of CLASSI_FIN or those classified as \"other viruses SRAG\")\n",
    "super_srag = super_srag.filter((F.col('CLASSI_FIN').isNotNull()) & (F.col('CLASSI_FIN') != '3'))\\\n",
    "                        .withColumn('CLASSI_FIN', F.when((F.col('CLASSI_FIN') == '1') | (F.col('CLASSI_FIN') == '2'), 'not-covid')\\\n",
    "                                                   .when(F.col('CLASSI_FIN') == '4', 'not-covid')\\\n",
    "                                                    .otherwise(F.lit('covid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting UF's list\n",
    "UFs = super_srag.select('SG_UF_NOT').groupBy('SG_UF_NOT').count().orderBy('SG_UF_NOT').select('SG_UF_NOT').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing amount of predicted cases accross epidemiological weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attr(classi_fin, classi_fin_source):\n",
    "    if classi_fin_source == 'predicted':\n",
    "        suffix = 'pred'\n",
    "    else: \n",
    "        suffix = 'ori'\n",
    "    return classi_fin + '-' + suffix\n",
    "udf_make_attr = F.udf(make_attr, StringType())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks = super_srag.groupBy(['ANO', 'epi_week_year', 'CLASSI_FIN', 'CLASSI_FIN_source']).agg({'CLASSI_FIN_source': 'count', 'CLASSI_FIN': 'count'}).orderBy(['ANO', 'epi_week_year']).select(['ANO', 'epi_week_year', 'CLASSI_FIN_source', 'CLASSI_FIN', 'count(CLASSI_FIN)']).withColumn('attr', udf_make_attr(F.col('CLASSI_FIN'), F.col('CLASSI_FIN_source')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering ss_weeks\n",
    "years = ['2020', '2021']\n",
    "ss_weeks = ss_weeks.filter(F.col('ANO').isin(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate and organize all epidemiological weeks automatically\n",
    "\n",
    "# # putting all epi_week_year tags in a list to create the bars on plot\n",
    "# weeks_cols = ss_weeks.select(['ANO', 'epi_week_year']).distinct().select('epi_week_year').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# # for some reason, there is a duplicate for epi_week_year '01-2020', we have to pop it\n",
    "# weeks_cols.pop(2)\n",
    "\n",
    "weeks_cols = ['01-2020', '02-2020', '03-2020', '04-2020', '05-2020', '06-2020', '07-2020', '08-2020', '09-2020', '10-2020', \n",
    " '11-2020', '12-2020', '13-2020', '14-2020', '15-2020', '16-2020', '17-2020', '18-2020', '19-2020', '20-2020',\n",
    " '21-2020', '22-2020', '23-2020', '24-2020', '25-2020', '26-2020', '27-2020', '28-2020', '29-2020', '30-2020',\n",
    " '31-2020', '32-2020', '33-2020', '34-2020', '35-2020', '36-2020', '37-2020', '38-2020', '39-2020', '40-2020', \n",
    " '41-2020', '42-2020', '43-2020', '44-2020', '45-2020', '46-2020', '47-2020', '48-2020', '49-2020', '50-2020',\n",
    " '51-2020', '52-2020', '53-2020', \n",
    " '01-2021', '02-2021', '03-2021', '04-2021', '05-2021', '06-2021','07-2021', '08-2021', '09-2021', '10-2021',\n",
    " '11-2021', '12-2021', '13-2021', '14-2021', '15-2021', '16-2021', '17-2021', '18-2021', '19-2021', '20-2021',\n",
    " '21-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a empty dataframe to join the counts for each epi_week after\n",
    "to_plot = spark.createDataFrame([\"covid-pred\", \"covid-ori\", \"not-covid-pred\", \"not-covid-ori\"], StringType()).toDF(\"attr\")\n",
    "\n",
    "# attaching the counts of each epi_week on the plot dataframe\n",
    "for week in weeks_cols:\n",
    "    week_counts = ss_weeks.filter(F.col('epi_week_year') == week).select(['attr', 'count(CLASSI_FIN)']).groupBy('attr').agg({'count(CLASSI_FIN)': 'sum'}).withColumnRenamed('sum(count(CLASSI_FIN))', week)\n",
    "    to_plot = to_plot.join(week_counts, 'attr', 'left')\n",
    "\n",
    "pd_to_plot = to_plot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cases (original and predicted) by epidemiological weeks\n",
    "pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "          colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "          figsize=(160,70))\n",
    "\n",
    "plt.xticks(fontsize=80, rotation=45)\n",
    "plt.yticks(fontsize=120)\n",
    "plt.legend(fontsize=150)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,70000])\n",
    "plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "plt.title(label=\"Final classification of cases after prediction - from jan/2020 to may/2021 - BR\", loc='center', fontsize=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing amount of predicted cases accross epidemiological weeks (for each state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uf in UFs:\n",
    "    y_min_lim = 0\n",
    "    if uf in ['SP', 'MG', 'RJ', 'RS']:\n",
    "        y_max_lim = 20000\n",
    "    else:\n",
    "        y_max_lim = 5000\n",
    "    # making the filtering, selecting and grouping data\n",
    "    ss_weeks = super_srag.filter(F.col('SG_UF_NOT') == uf)\\\n",
    "                         .groupBy(['ANO', 'epi_week_year', 'CLASSI_FIN', 'CLASSI_FIN_source']).agg({'CLASSI_FIN_source': 'count', 'CLASSI_FIN': 'count'}).orderBy(['ANO', 'epi_week_year']).select(['ANO', 'epi_week_year', 'CLASSI_FIN_source', 'CLASSI_FIN', 'count(CLASSI_FIN)']).withColumn('attr', udf_make_attr(F.col('CLASSI_FIN'), F.col('CLASSI_FIN_source')))\n",
    "\n",
    "    # setting the years to plot\n",
    "    years = ['2020', '2021']\n",
    "    ss_weeks = ss_weeks.filter(F.col('ANO').isin(years))\n",
    "\n",
    "\n",
    "    # creating a empty dataframe to join the counts for each epi_week after\n",
    "    to_plot = spark.createDataFrame([\"covid-pred\", \"covid-ori\", \"not-covid-pred\", \"not-covid-ori\"], StringType()).toDF(\"attr\")\n",
    "\n",
    "    # attaching the counts of each epi_week on the plot dataframe\n",
    "    for week in weeks_cols:\n",
    "        week_counts = ss_weeks.filter(F.col('epi_week_year') == week).select(['attr', 'count(CLASSI_FIN)']).groupBy('attr').agg({'count(CLASSI_FIN)': 'sum'}).withColumnRenamed('sum(count(CLASSI_FIN))', week)\n",
    "        to_plot = to_plot.join(week_counts, 'attr', 'left')\n",
    "\n",
    "    pd_to_plot = to_plot.toPandas()\n",
    "\n",
    "    \n",
    "    # plotting cases (original and predicted) by epidemiological weeks\n",
    "    pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "              colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "              figsize=(160,70))\n",
    "\n",
    "    plt.xticks(fontsize=80, rotation=45)\n",
    "    plt.yticks(fontsize=120)\n",
    "    plt.legend(fontsize=150)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([y_min_lim, y_max_lim])\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "    plt.title(label=\"Final classification of cases after prediction - from jan/2020 to may/2021 - \" + uf, loc='center', fontsize=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing amount of predicted outcomes accross epidemiological weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVOLUCAO\n",
    "# 1-Cura\n",
    "# 2-Óbito\n",
    "# 3- Óbito por outras causas\n",
    "# 9-Ignorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attr2(classi_fin, classi_fin_source, evolucao):\n",
    "    if classi_fin_source == 'predicted':\n",
    "        suffix = 'pred'\n",
    "    else: \n",
    "        suffix = 'ori'\n",
    "    \n",
    "    if evolucao == '1':\n",
    "        ev = 'recovered'\n",
    "    elif (evolucao == '2') or (evolucao == '3'):\n",
    "        ev = 'deaths'\n",
    "    else:\n",
    "        ev = 'ignored'\n",
    "    return classi_fin + '-' + suffix + '-' + ev\n",
    "udf_make_attr2 = F.udf(make_attr2, StringType())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks = super_srag.groupBy(['ANO', 'epi_week_year', 'EVOLUCAO', 'CLASSI_FIN', 'CLASSI_FIN_source']).agg({'CLASSI_FIN_source': 'count', 'CLASSI_FIN': 'count'}).orderBy(['ANO', 'epi_week_year']).select(['ANO', 'epi_week_year', 'EVOLUCAO', 'CLASSI_FIN_source', 'CLASSI_FIN', 'count(CLASSI_FIN)']).withColumn('attr', udf_make_attr2(F.col('CLASSI_FIN'), F.col('CLASSI_FIN_source'), F.col('EVOLUCAO')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering ss_weeks\n",
    "years = ['2020', '2021']\n",
    "ss_weeks = ss_weeks.filter(F.col('ANO').isin(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate and organize all epidemiological weeks automatically\n",
    "\n",
    "# # putting all epi_week_year tags in a list to create the bars on plot\n",
    "# weeks_cols = ss_weeks.select(['ANO', 'epi_week_year']).distinct().select('epi_week_year').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# # for some reason, there is a duplicate for epi_week_year '01-2020', we have to pop it\n",
    "# weeks_cols.pop(2)\n",
    "\n",
    "weeks_cols = ['01-2020', '02-2020', '03-2020', '04-2020', '05-2020', '06-2020', '07-2020', '08-2020', '09-2020', '10-2020', \n",
    " '11-2020', '12-2020', '13-2020', '14-2020', '15-2020', '16-2020', '17-2020', '18-2020', '19-2020', '20-2020',\n",
    " '21-2020', '22-2020', '23-2020', '24-2020', '25-2020', '26-2020', '27-2020', '28-2020', '29-2020', '30-2020',\n",
    " '31-2020', '32-2020', '33-2020', '34-2020', '35-2020', '36-2020', '37-2020', '38-2020', '39-2020', '40-2020', \n",
    " '41-2020', '42-2020', '43-2020', '44-2020', '45-2020', '46-2020', '47-2020', '48-2020', '49-2020', '50-2020',\n",
    " '51-2020', '52-2020', '53-2020', \n",
    " '01-2021', '02-2021', '03-2021', '04-2021', '05-2021', '06-2021','07-2021', '08-2021', '09-2021', '10-2021',\n",
    " '11-2021', '12-2021', '13-2021', '14-2021', '15-2021', '16-2021', '17-2021', '18-2021', '19-2021', '20-2021',\n",
    " '21-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a empty dataframe to join the counts for each epi_week after\n",
    "# to_plot = spark.createDataFrame([\"covid-pred-recovered\", \"covid-ori-recovered\", \"not-covid-pred-recovered\", \"not-covid-ori-recovered\",\n",
    "#                                  \"covid-pred-deaths\", \"covid-ori-deaths\", \"not-covid-pred-deaths\", \"not-covid-ori-deaths\",\n",
    "#                                  \"covid-pred-ignored\", \"covid-ori-ignored\", \"not-covid-pred-ignored\", \"not-covid-ori-ignored\",\n",
    "#                                 ], StringType()).toDF(\"attr\")\n",
    "\n",
    "to_plot = spark.createDataFrame([\"covid-pred-recovered\", \"covid-ori-recovered\",\n",
    "                                 \"covid-pred-deaths\", \"covid-ori-deaths\",\n",
    "                                 \"covid-pred-ignored\", \"covid-ori-ignored\"\n",
    "                                ], StringType()).toDF(\"attr\")\n",
    "\n",
    "\n",
    "# attaching the counts of each epi_week on the plot dataframe\n",
    "for week in weeks_cols:\n",
    "    week_counts = ss_weeks.filter(F.col('epi_week_year') == week).select(['attr', 'count(CLASSI_FIN)']).groupBy('attr').agg({'count(CLASSI_FIN)': 'sum'}).withColumnRenamed('sum(count(CLASSI_FIN))', week)\n",
    "    to_plot = to_plot.join(week_counts, 'attr', 'left')\n",
    "\n",
    "pd_to_plot = to_plot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "          colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "          figsize=(160,70))\n",
    "plt.xticks(fontsize=80, rotation=45)\n",
    "plt.yticks(fontsize=120)\n",
    "plt.legend(fontsize=150)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,70000])\n",
    "plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "plt.title(label=\"Evolution of cases - from jan/2020 to may/2021 - BR\", loc='center', fontsize=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting cases (original and predicted) by epidemiological weeks\n",
    "# pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "#           colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "#           figsize=(160,70))\n",
    "\n",
    "# plt.xticks(fontsize=80, rotation=45)\n",
    "# plt.yticks(fontsize=120)\n",
    "# plt.legend(fontsize=150)\n",
    "# axes = plt.gca()\n",
    "# axes.set_ylim([0,70000])\n",
    "# plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "# plt.title(label=\"Outcome of cases after prediction - from jan/2020 to may/2021 - BR\", loc='center', fontsize=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<hr />\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing amount of predicted outcomes accross epidemiological weeks (for each state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks.unpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uf in UFs:\n",
    "    y_min_lim = 0\n",
    "    if uf in ['SP', 'MG', 'RJ', 'RS']:\n",
    "        y_max_lim = 20000\n",
    "    else:\n",
    "        y_max_lim = 5000\n",
    "    # making the filtering, selecting and grouping data\n",
    "    ss_weeks = super_srag.filter(F.col('SG_UF_NOT') == uf)\\\n",
    "                         .groupBy(['ANO', 'epi_week_year', 'EVOLUCAO', 'CLASSI_FIN', 'CLASSI_FIN_source']).agg({'CLASSI_FIN_source': 'count', 'CLASSI_FIN': 'count'}).orderBy(['ANO', 'epi_week_year']).select(['ANO', 'epi_week_year', 'EVOLUCAO', 'CLASSI_FIN_source', 'CLASSI_FIN', 'count(CLASSI_FIN)']).withColumn('attr', udf_make_attr2(F.col('CLASSI_FIN'), F.col('CLASSI_FIN_source'), F.col('EVOLUCAO')))\n",
    "\n",
    "    # setting the years to plot\n",
    "    years = ['2020', '2021']\n",
    "    ss_weeks = ss_weeks.filter(F.col('ANO').isin(years))\n",
    "\n",
    "\n",
    "    # creating a empty dataframe to join the counts for each epi_week after\n",
    "    to_plot = spark.createDataFrame([\"covid-pred-recovered\", \"covid-ori-recovered\",\n",
    "                                 \"covid-pred-deaths\", \"covid-ori-deaths\",\n",
    "                                 \"covid-pred-ignored\", \"covid-ori-ignored\"\n",
    "                                ], StringType()).toDF(\"attr\")\n",
    "\n",
    "    # attaching the counts of each epi_week on the plot dataframe\n",
    "    for week in weeks_cols:\n",
    "        week_counts = ss_weeks.filter(F.col('epi_week_year') == week).select(['attr', 'count(CLASSI_FIN)']).groupBy('attr').agg({'count(CLASSI_FIN)': 'sum'}).withColumnRenamed('sum(count(CLASSI_FIN))', week)\n",
    "        to_plot = to_plot.join(week_counts, 'attr', 'left')\n",
    "\n",
    "    pd_to_plot = to_plot.toPandas()\n",
    "    \n",
    "    # plotting cases (original and predicted) by epidemiological weeks\n",
    "    pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "              colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "              figsize=(160,70))\n",
    "\n",
    "    plt.xticks(fontsize=80, rotation=45)\n",
    "    plt.yticks(fontsize=120)\n",
    "    plt.legend(fontsize=150)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([y_min_lim,y_max_lim])\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "    plt.title(label=\"Evolution of cases - from jan/2020 to may/2021 - \" + uf, loc='center', fontsize=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing amount of (original and predicted) cases at different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_age_group = {\n",
    "                    '01': '< 1',\n",
    "                    '02': '1 to 5',\n",
    "                    '03': '10 to 19', \n",
    "                    '04': '20 to 29', \n",
    "                    '05': '30 to 39', \n",
    "                    '06': '40 to 49', \n",
    "                    '07': '50 to 59',\n",
    "                    '08': '60 to 69',\n",
    "                    '09': '70 to 79',\n",
    "                    '10': '80 to 89',\n",
    "                    '11': '>= 90',\n",
    "                    '12': 'NA'\n",
    "                 }\n",
    "\n",
    "age_groups = list(dict_age_group.keys())\n",
    "age_group_names = list(dict_age_group.values())\n",
    "# ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag = super_srag.withColumn('AGE_GROUP', F.col('AGE_GROUP').cast('string'))\\\n",
    "                       .withColumn('AGE_GROUP', F.lpad(F.col('AGE_GROUP'), 2, '0'))\n",
    "\n",
    "super_srag = super_srag.withColumn('AGE_GROUP_', F.lit(None))\n",
    "                      \n",
    "for age_group in age_groups:\n",
    "    super_srag = super_srag.withColumn('AGE_GROUP_', F.when(F.col('AGE_GROUP') == age_group, dict_age_group[age_group]).otherwise(F.col('AGE_GROUP_')))\n",
    "\n",
    "# 1. < 1\n",
    "# 2. 1 to 5 \n",
    "# 3. 10 to 19 \n",
    "# 4. 20 to 29 \n",
    "# 5. 30 to 39 \n",
    "# 6. 40 to 49 \n",
    "# 7. 50 to 59 \n",
    "# 8. 60 to 69 \n",
    "# 9. 70 to 79\n",
    "# 10. 80 to 89\n",
    "# 11. >= 90\n",
    "# 12. NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_srag.select('AGE_GROUP', 'AGE_GROUP_')\\\n",
    "          .groupBy(['AGE_GROUP', 'AGE_GROUP_']).count().orderBy('AGE_GROUP').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_attr(classi_fin, classi_fin_source):\n",
    "    if classi_fin_source == 'predicted':\n",
    "        suffix = 'pred'\n",
    "    else: \n",
    "        suffix = 'ori'\n",
    "    return classi_fin + '-' + suffix\n",
    "udf_make_attr = F.udf(make_attr, StringType())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks = super_srag.groupBy(['ANO', 'epi_week_year', 'AGE_GROUP_', 'CLASSI_FIN', 'CLASSI_FIN_source']).agg({'CLASSI_FIN_source': 'count', 'CLASSI_FIN': 'count'}).orderBy(['ANO', 'epi_week_year']).select(['ANO', 'epi_week_year', 'AGE_GROUP_', 'CLASSI_FIN_source', 'CLASSI_FIN', 'count(CLASSI_FIN)']).withColumn('attr', udf_make_attr(F.col('CLASSI_FIN'), F.col('CLASSI_FIN_source')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering ss_weeks\n",
    "years = ['2020', '2021']\n",
    "ss_weeks = ss_weeks.filter(F.col('ANO').isin(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate and organize all epidemiological weeks automatically\n",
    "\n",
    "# # putting all epi_week_year tags in a list to create the bars on plot\n",
    "# weeks_cols = ss_weeks.select(['ANO', 'epi_week_year']).distinct().select('epi_week_year').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# # for some reason, there is a duplicate for epi_week_year '01-2020', we have to pop it\n",
    "# weeks_cols.pop(2)\n",
    "\n",
    "weeks_cols = ['01-2020', '02-2020', '03-2020', '04-2020', '05-2020', '06-2020', '07-2020', '08-2020', '09-2020', '10-2020', \n",
    " '11-2020', '12-2020', '13-2020', '14-2020', '15-2020', '16-2020', '17-2020', '18-2020', '19-2020', '20-2020',\n",
    " '21-2020', '22-2020', '23-2020', '24-2020', '25-2020', '26-2020', '27-2020', '28-2020', '29-2020', '30-2020',\n",
    " '31-2020', '32-2020', '33-2020', '34-2020', '35-2020', '36-2020', '37-2020', '38-2020', '39-2020', '40-2020', \n",
    " '41-2020', '42-2020', '43-2020', '44-2020', '45-2020', '46-2020', '47-2020', '48-2020', '49-2020', '50-2020',\n",
    " '51-2020', '52-2020', '53-2020', \n",
    " '01-2021', '02-2021', '03-2021', '04-2021', '05-2021', '06-2021','07-2021', '08-2021', '09-2021', '10-2021',\n",
    " '11-2021', '12-2021', '13-2021', '14-2021', '15-2021', '16-2021', '17-2021', '18-2021', '19-2021', '20-2021',\n",
    " '21-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_weeks.filter((F.col('epi_week_year') == '53-2020') & (F.col('attr') == 'covid-pred')).select(['AGE_GROUP_', 'attr', 'count(CLASSI_FIN)']).groupBy(['AGE_GROUP_', 'attr']).sum().withColumnRenamed('sum(count(CLASSI_FIN))', '53-2020').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a empty dataframe to join the counts for each epi_week after\n",
    "to_plot = spark.createDataFrame(age_group_names, StringType()).toDF(\"AGE_GROUP_\")\n",
    "\n",
    "# attaching the counts of each epi_week on the plot dataframe\n",
    "for week in weeks_cols:\n",
    "    week_counts = ss_weeks.filter((F.col('epi_week_year') == week) & (F.col('attr') == 'covid-pred')).select(['AGE_GROUP_', 'attr', 'count(CLASSI_FIN)']).groupBy(['AGE_GROUP_', 'attr']).sum().withColumnRenamed('sum(count(CLASSI_FIN))', week).select(['AGE_GROUP_', week])\n",
    "    to_plot = to_plot.join(week_counts, 'AGE_GROUP_', 'left')\n",
    "\n",
    "pd_to_plot = to_plot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapa de calor para age group x epi week\n",
    "\n",
    "plt.pcolor(pd_to_plot.set_index('AGE_GROUP_'))\n",
    "plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cases (original and predicted) by epidemiological weeks\n",
    "pd_to_plot.set_index('attr').T.plot(kind='bar', stacked=True,\n",
    "          colormap=ListedColormap(sns.color_palette()), width=0.5,\n",
    "          figsize=(160,70))\n",
    "\n",
    "plt.xticks(fontsize=80, rotation=45)\n",
    "plt.yticks(fontsize=120)\n",
    "plt.legend(fontsize=150)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,70000])\n",
    "plt.grid(color='gray', linestyle='-', linewidth=2)\n",
    "plt.title(label=\"Final classification of cases after prediction - from jan/2020 to may/2021 - BR\", loc='center', fontsize=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapa de calor para age group x epi week\n",
    "\n",
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = ['aaa', 'bbb', 'ccc', 'ddd', 'eee']\n",
    "columns = ['A', 'B', 'C', 'D']\n",
    "df = DataFrame(abs(np.random.randn(5, 4)), index=index, columns=columns)\n",
    "\n",
    "plt.pcolor(df)\n",
    "plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
